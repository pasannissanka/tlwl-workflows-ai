{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:35:37.509767Z",
     "start_time": "2025-10-23T14:35:28.975974Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               bookmark_id  \\\n",
      "0     a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "1     a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "2     a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "3     06ba62ab-870f-432a-87a6-a5be07f7b2e6   \n",
      "4     06ba62ab-870f-432a-87a6-a5be07f7b2e6   \n",
      "...                                    ...   \n",
      "2132  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "2133  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "2134  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "2135  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "2136  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "\n",
      "                                                    url  \\\n",
      "0                https://www.latent.space/p/2025-papers   \n",
      "1                https://www.latent.space/p/2025-papers   \n",
      "2                https://www.latent.space/p/2025-papers   \n",
      "3     https://www.interconnects.ai/p/papers-im-readi...   \n",
      "4     https://www.interconnects.ai/p/papers-im-readi...   \n",
      "...                                                 ...   \n",
      "2132                   https://arxiv.org/abs/2502.19587   \n",
      "2133                   https://arxiv.org/abs/2502.19587   \n",
      "2134                   https://arxiv.org/abs/2502.19587   \n",
      "2135                   https://arxiv.org/abs/2502.19587   \n",
      "2136                   https://arxiv.org/abs/2502.19587   \n",
      "\n",
      "                                                  title  \\\n",
      "0                  The 2025 AI Engineering Reading List   \n",
      "1                  The 2025 AI Engineering Reading List   \n",
      "2                  The 2025 AI Engineering Reading List   \n",
      "3     Recent reasoning research: GRPO tweaks, base m...   \n",
      "4     Recent reasoning research: GRPO tweaks, base m...   \n",
      "...                                                 ...   \n",
      "2132                    NeoBERT: A Next-Generation BERT   \n",
      "2133                    NeoBERT: A Next-Generation BERT   \n",
      "2134                    NeoBERT: A Next-Generation BERT   \n",
      "2135                    NeoBERT: A Next-Generation BERT   \n",
      "2136                    NeoBERT: A Next-Generation BERT   \n",
      "\n",
      "                                            description language  \\\n",
      "0     We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "1     We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "2     We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "3     The papers I endorse as worth reading among a ...       en   \n",
      "4     The papers I endorse as worth reading among a ...       en   \n",
      "...                                                 ...      ...   \n",
      "2132  Recent innovations in architecture, pre-traini...       en   \n",
      "2133  Recent innovations in architecture, pre-traini...       en   \n",
      "2134  Recent innovations in architecture, pre-traini...       en   \n",
      "2135  Recent innovations in architecture, pre-traini...       en   \n",
      "2136  Recent innovations in architecture, pre-traini...       en   \n",
      "\n",
      "                  created_at              updated_at  \\\n",
      "0    2025-10-23 12:35:18.812 2025-10-23 12:35:18.812   \n",
      "1    2025-10-23 12:35:18.812 2025-10-23 12:35:18.812   \n",
      "2    2025-10-23 12:35:18.812 2025-10-23 12:35:18.812   \n",
      "3    2025-10-23 12:35:36.480 2025-10-23 12:35:36.480   \n",
      "4    2025-10-23 12:35:36.480 2025-10-23 12:35:36.480   \n",
      "...                      ...                     ...   \n",
      "2132 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080   \n",
      "2133 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080   \n",
      "2134 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080   \n",
      "2135 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080   \n",
      "2136 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080   \n",
      "\n",
      "                                    tag_id              key             name  \n",
      "0     d73bda20-81cf-4ac2-8d73-f782b68a1901               ai               ai  \n",
      "1     23ad99a1-37e5-43dd-bd41-3ac8589cfe6f      engineering      engineering  \n",
      "2     886e8c54-87e1-4933-85d4-8520c12321cb          reading          reading  \n",
      "3     bc9adf25-5567-4aba-abfe-3fb1f5d0e146         research         research  \n",
      "4     b0e3906d-3109-41a0-befa-8de4bd72b3a1        reasoning        reasoning  \n",
      "...                                    ...              ...              ...  \n",
      "2132  f361ee75-db2e-44ff-aa49-f09cbd8e44da         problems         problems  \n",
      "2133  5fe40731-7bf9-4b73-9e15-bb26b07ac559        solutions        solutions  \n",
      "2134  9b950bc7-154d-469b-a8d7-61826a62872c           vision           vision  \n",
      "2135  c608b9e1-59e0-4186-bb95-0dbb94ec435d             data             data  \n",
      "2136  46dc4d80-f29c-400e-a2a3-00b93416f099  representations  representations  \n",
      "\n",
      "[2137 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from topic_gen.input.inject_data import InjectData\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "inject = InjectData()\n",
    "\n",
    "user_id = \"8c525b6b-27c9-4379-a454-2c3b3a781124\"\n",
    "\n",
    "df = inject.query_bookmarks(user_id)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82166c598cce5d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:35:48.493225Z",
     "start_time": "2025-10-23T14:35:48.319609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   tag_id          key         name  \\\n",
      "0    00608d78-5556-4e9a-8b0c-ce2796f9f13d         qwen         qwen   \n",
      "1    006adf0c-c6bc-44b3-90f6-cc9f524a90e0  challenging  challenging   \n",
      "2    03b8761c-7c70-42d5-bf1a-e04aa63c36b5      testing      testing   \n",
      "3    07db4626-c83f-4ac5-86d4-e49ab2af51a0      scaling      scaling   \n",
      "4    07e2bc25-09ac-4491-bd68-b52bbbf29059    detection    detection   \n",
      "..                                    ...          ...          ...   \n",
      "166  f829442a-a48f-4b74-86dc-2241ddcdbe28      metrics      metrics   \n",
      "167  f9aaf4e8-18e2-4f48-af22-4a044c4def8d      pixtral      pixtral   \n",
      "168  fab1bd45-c87f-4267-aa29-65a4ceabb690  fine-tuning  fine tuning   \n",
      "169  fe0fcf88-552b-4479-b1a1-6838d08eb490       images       images   \n",
      "170  fee44b01-a2dd-4a65-bb39-51999613b207      dataset      dataset   \n",
      "\n",
      "                                             bookmarks  \n",
      "0    [{'bookmark_id': 'c6c0d547-a5de-4d68-9a48-c2f0...  \n",
      "1    [{'bookmark_id': 'c23de130-b490-48d1-b3d8-71e6...  \n",
      "2    [{'bookmark_id': 'c273f876-3bb8-4b0f-a7d0-c064...  \n",
      "3    [{'bookmark_id': '80095e27-6b62-4ff4-84f6-5c94...  \n",
      "4    [{'bookmark_id': 'f8a6437d-1758-4456-8006-e73e...  \n",
      "..                                                 ...  \n",
      "166  [{'bookmark_id': '20e7f9d5-cf43-49ca-a232-74bf...  \n",
      "167  [{'bookmark_id': '9006090a-94ba-4ee4-b92b-a57e...  \n",
      "168  [{'bookmark_id': '42e8404b-5600-4f15-8fe4-14e8...  \n",
      "169  [{'bookmark_id': '8c5c6882-01ec-46b3-9994-7291...  \n",
      "170  [{'bookmark_id': '30ad7349-c883-4a59-9ee4-903a...  \n",
      "\n",
      "[171 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\AppData\\Local\\Temp\\ipykernel_243824\\2450164243.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby([\"tag_id\", \"key\", \"name\"]).apply(lambda g: g[[\n"
     ]
    }
   ],
   "source": [
    "grouped_df = (\n",
    "    df.groupby([\"tag_id\", \"key\", \"name\"]).apply(lambda g: g[[\n",
    "        \"bookmark_id\", \"title\", \"description\", \"language\", \"created_at\", \"updated_at\",\n",
    "    ]].to_dict(orient=\"records\"))\n",
    "    .reset_index(name=\"bookmarks\")\n",
    ")\n",
    "\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8477b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = df.copy()\n",
    "\n",
    "# Remove rows with empty title\n",
    "validated_df = validated_df[validated_df[\"title\"].notna()]\n",
    "\n",
    "# Remove rows with empty url\n",
    "validated_df = validated_df[validated_df[\"url\"].notna()]\n",
    "\n",
    "# Remove rows with empty tag key\n",
    "validated_df = validated_df[validated_df[\"key\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cbc8fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai' 'engineering' 'reading' 'research' 'reasoning' 'model'\n",
      " 'reinforcement' 'curation' 'chatgpt' 'api' 'realtime' 'mathematics'\n",
      " 'language' 'deeplearning' 'experts' 'mixtral' 'pixtral' 'optimization'\n",
      " 'performance' 'programming' 'intelligence' 'coding' 'tools' 'deepseek'\n",
      " 'llm' 'scaling' 'longtermism' 'mistral' 'llama' 'chat' 'fine' 'tuning'\n",
      " 'gpt' 'report' 'models' 'segment' 'images' 'videos' 'speech'\n",
      " 'recognition' 'supervision' 'learning' 'transferable' 'visual' 'deep'\n",
      " 'large' 'scale' 'multimodal' 'shortcomings' 'exploration' 'object'\n",
      " 'detection' 'unified' 'code' 'generation' 'prompt' 'segmentation'\n",
      " 'sonnet' 'agents' 'computer' 'stack' 'source' 'licensing' 'memory'\n",
      " 'papers' 'systems' 'implementation' 'architecture' 'huggingface'\n",
      " 'benchmark' 'github' 'issues' 'benchmarks' 'system' 'hallucinations'\n",
      " 'facts' 'building' 'retrieval' 'augmented' 'chatbots' 'evaluation'\n",
      " 'embedding' 'datasets' 'capabilities' 'advancements' 'mteb' 'knowledge'\n",
      " 'nlp' 'tasks' 'embeddings' 'context' 'power' 'parameter' 'efficiency'\n",
      " 'problem' 'solving' 'prompting' 'training' 'proof' 'questions' 'testing'\n",
      " 'custom' 'metrics' 'mathematical' 'accuracy' 'augmentation' 'structure'\n",
      " 'queries' 'multitask' 'understanding' 'problems' 'solutions']\n"
     ]
    }
   ],
   "source": [
    "# Group by tag_id, key, and name, then count bookmarks for each tag_id\n",
    "bookmark_counts = validated_df.groupby([\"tag_id\", \"key\", \"name\"]).size().reset_index(name=\"bookmark_count\")\n",
    "\n",
    "# Filter tags with more than 5 bookmarks\n",
    "filtered_tags = bookmark_counts[bookmark_counts[\"bookmark_count\"] > 5]\n",
    "\n",
    "# print(filtered_tags)\n",
    "\n",
    "# Filter the original dataframe to only include bookmarks with the filtered tags\n",
    "filtered_df = validated_df[validated_df[\"tag_id\"].isin(filtered_tags[\"tag_id\"])]\n",
    "\n",
    "# print(filtered_df)\n",
    "\n",
    "tag_keys_df = filtered_df[[\"tag_id\", \"key\"]].drop_duplicates()\n",
    "\n",
    "print(tag_keys_df[\"key\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb61ee9",
   "metadata": {},
   "source": [
    "### Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d461a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 16 16  4  6  4  5 14  1  0 18  5 17  4  8  8  3  2  1  4  1  2 17\n",
      " 11  3  2  8 11 14  5  3  1 15  6  0  0  0  5  0  4  4  5  0 17  5  3  0\n",
      "  2  4  5  0  6  1  5 12  0 11  4  5 11 15  1  5 16  7  6  6 11 10  1  9\n",
      " 10  7  8 15  6 16  2 14  2 13 10  2  2 11  4  5  7 13  5  5  3  2  9  9\n",
      " 12  4 15 16 16  5 10 18 10  2  6 16  7  4  9  9]\n",
      "                                    tag_id            key  cluster\n",
      "0     d73bda20-81cf-4ac2-8d73-f782b68a1901             ai        4\n",
      "1     23ad99a1-37e5-43dd-bd41-3ac8589cfe6f    engineering        2\n",
      "2     886e8c54-87e1-4933-85d4-8520c12321cb        reading       16\n",
      "3     bc9adf25-5567-4aba-abfe-3fb1f5d0e146       research       16\n",
      "4     b0e3906d-3109-41a0-befa-8de4bd72b3a1      reasoning        4\n",
      "...                                    ...            ...      ...\n",
      "1288  ba56e98b-1fab-48a9-8471-19fc1504fba7        queries       16\n",
      "1398  59d692d2-ad20-4110-bd7b-a46d0cd9ad40      multitask        7\n",
      "1399  ebaad30e-c0f2-4401-a6fb-be52a6ca6c7a  understanding        4\n",
      "1425  f361ee75-db2e-44ff-aa49-f09cbd8e44da       problems        9\n",
      "1507  5fe40731-7bf9-4b73-9e15-bb26b07ac559      solutions        9\n",
      "\n",
      "[112 rows x 3 columns]\n",
      "Cluster 4:\n",
      "['ai', 'reasoning', 'reinforcement', 'experts', 'intelligence', 'supervision', 'learning', 'exploration', 'agents', 'knowledge', 'training', 'understanding']\n",
      "\n",
      "Cluster 2:\n",
      "['engineering', 'performance', 'tools', 'longtermism', 'shortcomings', 'augmented', 'evaluation', 'capabilities', 'advancements', 'efficiency', 'augmentation']\n",
      "\n",
      "Cluster 16:\n",
      "['reading', 'research', 'papers', 'retrieval', 'questions', 'testing', 'queries']\n",
      "\n",
      "Cluster 6:\n",
      "['model', 'models', 'unified', 'implementation', 'architecture', 'building', 'structure']\n",
      "\n",
      "Cluster 5:\n",
      "['curation', 'language', 'fine', 'speech', 'transferable', 'large', 'object', 'generation', 'computer', 'memory', 'nlp', 'context', 'power', 'custom']\n",
      "\n",
      "Cluster 14:\n",
      "['chatgpt', 'chat', 'chatbots']\n",
      "\n",
      "Cluster 1:\n",
      "['api', 'programming', 'coding', 'gpt', 'code', 'licensing', 'github']\n",
      "\n",
      "Cluster 0:\n",
      "['realtime', 'segment', 'images', 'videos', 'recognition', 'visual', 'multimodal', 'detection', 'segmentation']\n",
      "\n",
      "Cluster 18:\n",
      "['mathematics', 'mathematical']\n",
      "\n",
      "Cluster 17:\n",
      "['deeplearning', 'deepseek', 'deep']\n",
      "\n",
      "Cluster 8:\n",
      "['mixtral', 'pixtral', 'mistral', 'hallucinations']\n",
      "\n",
      "Cluster 3:\n",
      "['optimization', 'scaling', 'tuning', 'scale', 'parameter']\n",
      "\n",
      "Cluster 11:\n",
      "['llm', 'llama', 'sonnet', 'stack', 'huggingface', 'mteb']\n",
      "\n",
      "Cluster 15:\n",
      "['report', 'source', 'facts', 'proof']\n",
      "\n",
      "Cluster 12:\n",
      "['prompt', 'prompting']\n",
      "\n",
      "Cluster 7:\n",
      "['systems', 'system', 'tasks', 'multitask']\n",
      "\n",
      "Cluster 10:\n",
      "['benchmark', 'benchmarks', 'datasets', 'metrics', 'accuracy']\n",
      "\n",
      "Cluster 9:\n",
      "['issues', 'problem', 'solving', 'problems', 'solutions']\n",
      "\n",
      "Cluster 13:\n",
      "['embedding', 'embeddings']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLUSTERING\n",
    "from topic_gen.clustering.cluster import AgglomerativeCluster, KMeansCluster\n",
    "\n",
    "\n",
    "cluster = AgglomerativeCluster()\n",
    "# kmeans_cluster = KMeansCluster(n_clusters=10)\n",
    "\n",
    "# kmeans_cluster_df = kmeans_cluster.fit(filtered_df)\n",
    "\n",
    "cluster_df = cluster.fit(tag_keys_df)\n",
    "print(cluster_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c728b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4:\n",
      "['ai', 'reasoning', 'reinforcement', 'experts', 'intelligence', 'supervision', 'learning', 'exploration', 'agents', 'knowledge', 'training', 'understanding'] 12\n",
      "\n",
      "Cluster 2:\n",
      "['engineering', 'performance', 'tools', 'longtermism', 'shortcomings', 'augmented', 'evaluation', 'capabilities', 'advancements', 'efficiency', 'augmentation'] 11\n",
      "\n",
      "Cluster 16:\n",
      "['reading', 'research', 'papers', 'retrieval', 'questions', 'testing', 'queries'] 7\n",
      "\n",
      "Cluster 6:\n",
      "['model', 'models', 'unified', 'implementation', 'architecture', 'building', 'structure'] 7\n",
      "\n",
      "Cluster 5:\n",
      "['curation', 'language', 'fine', 'speech', 'transferable', 'large', 'object', 'generation', 'computer', 'memory', 'nlp', 'context', 'power', 'custom'] 14\n",
      "\n",
      "Cluster 14:\n",
      "['chatgpt', 'chat', 'chatbots'] 3\n",
      "\n",
      "Cluster 1:\n",
      "['api', 'programming', 'coding', 'gpt', 'code', 'licensing', 'github'] 7\n",
      "\n",
      "Cluster 0:\n",
      "['realtime', 'segment', 'images', 'videos', 'recognition', 'visual', 'multimodal', 'detection', 'segmentation'] 9\n",
      "\n",
      "Cluster 18:\n",
      "['mathematics', 'mathematical'] 2\n",
      "\n",
      "Cluster 17:\n",
      "['deeplearning', 'deepseek', 'deep'] 3\n",
      "\n",
      "Cluster 8:\n",
      "['mixtral', 'pixtral', 'mistral', 'hallucinations'] 4\n",
      "\n",
      "Cluster 3:\n",
      "['optimization', 'scaling', 'tuning', 'scale', 'parameter'] 5\n",
      "\n",
      "Cluster 11:\n",
      "['llm', 'llama', 'sonnet', 'stack', 'huggingface', 'mteb'] 6\n",
      "\n",
      "Cluster 15:\n",
      "['report', 'source', 'facts', 'proof'] 4\n",
      "\n",
      "Cluster 12:\n",
      "['prompt', 'prompting'] 2\n",
      "\n",
      "Cluster 7:\n",
      "['systems', 'system', 'tasks', 'multitask'] 4\n",
      "\n",
      "Cluster 10:\n",
      "['benchmark', 'benchmarks', 'datasets', 'metrics', 'accuracy'] 5\n",
      "\n",
      "Cluster 9:\n",
      "['issues', 'problem', 'solving', 'problems', 'solutions'] 5\n",
      "\n",
      "Cluster 13:\n",
      "['embedding', 'embeddings'] 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print keys belonging to each cluster\n",
    "for cluster_id in cluster_df[\"cluster\"].unique():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    keys = cluster_df[cluster_df[\"cluster\"] == cluster_id][\"key\"].tolist()\n",
    "    print(keys, len(keys))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6388eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 tag_id key_x  cluster  \\\n",
      "0  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "1  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "2  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "3  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "4  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "5  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "6  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "7  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "8  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "9  d73bda20-81cf-4ac2-8d73-f782b68a1901    ai        4   \n",
      "\n",
      "                            bookmark_id  \\\n",
      "0  a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "1  06ba62ab-870f-432a-87a6-a5be07f7b2e6   \n",
      "2  802b1856-b4cf-4b0b-bcac-b65149c9213a   \n",
      "3  1785c3fe-0ec1-4208-ada2-f0366d510e1a   \n",
      "4  94c217e4-d35f-442d-9d76-6a2561b15caf   \n",
      "5  f6a8e377-0b53-4f09-bf43-777582c77721   \n",
      "6  9006090a-94ba-4ee4-b92b-a57e2ff0f508   \n",
      "7  00897913-7341-4b14-b64e-5cf88725e274   \n",
      "8  80095e27-6b62-4ff4-84f6-5c942b64d59e   \n",
      "9  8afb7bbd-e072-436f-8811-2664fc9bedcb   \n",
      "\n",
      "                                                 url  \\\n",
      "0             https://www.latent.space/p/2025-papers   \n",
      "1  https://www.interconnects.ai/p/papers-im-readi...   \n",
      "2                  https://openai.com/index/chatgpt/   \n",
      "3            https://www.latent.space/p/realtime-api   \n",
      "4                   https://arxiv.org/abs/2402.03300   \n",
      "5                   https://arxiv.org/abs/2401.04088   \n",
      "6                   https://arxiv.org/abs/2410.07073   \n",
      "7                   https://arxiv.org/abs/2401.14196   \n",
      "8                   https://arxiv.org/abs/2401.02954   \n",
      "9                   https://arxiv.org/abs/2310.06825   \n",
      "\n",
      "                                               title  \\\n",
      "0               The 2025 AI Engineering Reading List   \n",
      "1  Recent reasoning research: GRPO tweaks, base m...   \n",
      "2                                Introducing ChatGPT   \n",
      "3            OpenAI Realtime API: The Missing Manual   \n",
      "4  DeepSeekMath: Pushing the Limits of Mathematic...   \n",
      "5                                 Mixtral of Experts   \n",
      "6                                        Pixtral 12B   \n",
      "7  DeepSeek-Coder: When the Large Language Model ...   \n",
      "8  DeepSeek LLM: Scaling Open-Source Language Mod...   \n",
      "9                                         Mistral 7B   \n",
      "\n",
      "                                         description language  \\\n",
      "0  We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "1  The papers I endorse as worth reading among a ...       en   \n",
      "2  Weâ€™ve trained a model called ChatGPT which int...    en-US   \n",
      "3  Everything we learned, and everything we think...       en   \n",
      "4  Mathematical reasoning poses a significant cha...       en   \n",
      "5  We introduce Mixtral 8x7B, a Sparse Mixture of...       en   \n",
      "6  We introduce Pixtral-12B, a 12--billion-parame...       en   \n",
      "7  The rapid development of large language models...       en   \n",
      "8  The rapid development of open-source large lan...       en   \n",
      "9  We introduce Mistral 7B v0.1, a 7-billion-para...       en   \n",
      "\n",
      "               created_at              updated_at key_y name  \n",
      "0 2025-10-23 12:35:18.812 2025-10-23 12:35:18.812    ai   ai  \n",
      "1 2025-10-23 12:35:36.480 2025-10-23 12:35:36.480    ai   ai  \n",
      "2 2025-10-23 12:36:13.336 2025-10-23 12:36:13.336    ai   ai  \n",
      "3 2025-10-23 12:36:16.386 2025-10-23 12:36:16.386    ai   ai  \n",
      "4 2025-10-23 12:41:13.177 2025-10-23 12:41:13.177    ai   ai  \n",
      "5 2025-10-23 12:41:40.828 2025-10-23 12:41:40.828    ai   ai  \n",
      "6 2025-10-23 12:41:43.611 2025-10-23 12:41:43.611    ai   ai  \n",
      "7 2025-10-23 12:41:32.368 2025-10-23 12:41:32.368    ai   ai  \n",
      "8 2025-10-23 12:41:36.609 2025-10-23 12:41:36.609    ai   ai  \n",
      "9 2025-10-23 12:41:46.997 2025-10-23 12:41:46.997    ai   ai  \n"
     ]
    }
   ],
   "source": [
    "joined_df = pd.merge(cluster_df, filtered_df, on=\"tag_id\", how=\"left\")\n",
    "print(joined_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2acf835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = joined_df.drop(columns=[\"key_x\"])\n",
    "cleaned_df = cleaned_df.rename(columns={\"key_y\": \"key\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4b2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4:\n",
      "['ai', 'reasoning', 'reinforcement', 'experts', 'intelligence', 'supervision', 'learning', 'exploration', 'agents', 'knowledge', 'training', 'understanding'] 12\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206182F22D0> 59\n",
      "\n",
      "Cluster 2:\n",
      "['engineering', 'performance', 'tools', 'longtermism', 'shortcomings', 'augmented', 'evaluation', 'capabilities', 'advancements', 'efficiency', 'augmentation'] 11\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A8C8F0> 60\n",
      "\n",
      "Cluster 16:\n",
      "['reading', 'research', 'papers', 'retrieval', 'questions', 'testing', 'queries'] 7\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A9D9A0> 57\n",
      "\n",
      "Cluster 6:\n",
      "['model', 'models', 'unified', 'implementation', 'architecture', 'building', 'structure'] 7\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A9DEB0> 57\n",
      "\n",
      "Cluster 5:\n",
      "['curation', 'language', 'fine', 'speech', 'transferable', 'large', 'object', 'generation', 'computer', 'memory', 'nlp', 'context', 'power', 'custom'] 14\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A8B4D0> 57\n",
      "\n",
      "Cluster 14:\n",
      "['chatgpt', 'chat', 'chatbots'] 3\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206171AB0B0> 39\n",
      "\n",
      "Cluster 1:\n",
      "['api', 'programming', 'coding', 'gpt', 'code', 'licensing', 'github'] 7\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A88620> 43\n",
      "\n",
      "Cluster 0:\n",
      "['realtime', 'segment', 'images', 'videos', 'recognition', 'visual', 'multimodal', 'detection', 'segmentation'] 9\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002061870F4D0> 46\n",
      "\n",
      "Cluster 18:\n",
      "['mathematics', 'mathematical'] 2\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618A8C8F0> 27\n",
      "\n",
      "Cluster 17:\n",
      "['deeplearning', 'deepseek', 'deep'] 3\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020618AAB5F0> 47\n",
      "\n",
      "Cluster 8:\n",
      "['mixtral', 'pixtral', 'mistral', 'hallucinations'] 4\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206186F4320> 24\n",
      "\n",
      "Cluster 3:\n",
      "['optimization', 'scaling', 'tuning', 'scale', 'parameter'] 5\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206186F05F0> 47\n",
      "\n",
      "Cluster 11:\n",
      "['llm', 'llama', 'sonnet', 'stack', 'huggingface', 'mteb'] 6\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002061870CE60> 33\n",
      "\n",
      "Cluster 15:\n",
      "['report', 'source', 'facts', 'proof'] 4\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206186F54C0> 23\n",
      "\n",
      "Cluster 12:\n",
      "['prompt', 'prompting'] 2\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020617016750> 14\n",
      "\n",
      "Cluster 7:\n",
      "['systems', 'system', 'tasks', 'multitask'] 4\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002061870CE60> 29\n",
      "\n",
      "Cluster 10:\n",
      "['benchmark', 'benchmarks', 'datasets', 'metrics', 'accuracy'] 5\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206185EA930> 30\n",
      "\n",
      "Cluster 9:\n",
      "['issues', 'problem', 'solving', 'problems', 'solutions'] 5\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206185EAB10> 21\n",
      "\n",
      "Cluster 13:\n",
      "['embedding', 'embeddings'] 2\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000206185EB9B0> 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print keys belonging to each cluster\n",
    "for cluster_id in cleaned_df[\"cluster\"].unique():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    keys_df = cleaned_df[cleaned_df[\"cluster\"] == cluster_id][\"key\"]\n",
    "    keys = keys_df.unique().tolist()\n",
    "    bookmarks_df = cleaned_df[cleaned_df[\"cluster\"] == cluster_id]\n",
    "    bookmarks = bookmarks_df.groupby([\"bookmark_id\",\"title\", \"description\", \"language\", \"created_at\", \"updated_at\"])\n",
    "    print(keys, len(keys))\n",
    "    print(bookmarks, len(bookmarks))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6393b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The 2025 AI Engineering Reading List', 'Recent reasoning research: GRPO tweaks, base model RL, and data curation', 'Introducing ChatGPT', 'OpenAI Realtime API: The Missing Manual', 'DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models', 'Mixtral of Experts', 'Pixtral 12B', 'DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence', 'DeepSeek LLM: Scaling Open-Source Language Models with Longtermism', 'Mistral 7B', 'LLaMA: Open and Efficient Foundation Language Models', 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'GPT-4 Technical Report', 'The Llama 3 Herd of Models', 'SAM 2: Segment Anything in Images and Videos', 'Robust Speech Recognition via Large-Scale Weak Supervision', 'Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs', 'The new Claude 3.5 Sonnet, Computer Use, and Building SOTA Agents â€” with Erik Schluntz, Anthropic', 'Voyager: An Open-Ended Embodied Agent with Large Language Models', 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face', 'Toolformer: Language Models Can Teach Themselves to Use Tools', 'Introducing the SWE-Lancer benchmark', 'Extrinsic Hallucinations in LLMs', 'Ragas: Automated Evaluation of Retrieval Augmented Generation', 'Zach Nussbaum on X: \"ðŸ§µ Excited to announce modernbert-embed-base, a new embedding model built on the newly released ModernBERT! \\n\\nTrained on the public Nomic Embed datasets, modernbert-embed-base is a ~nomic-embed~ quality model with Matryoshka capabilities and brings the great advances of https://t.co/zBpt7RM9G4\" / X', 'The MTEB benchmark is dead | Hacker News', 'MTEB: Massive Text Embedding Benchmark', 'Why â€œContext Engineeringâ€ Matters', 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models', 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models', 'kalomaze on X: \"here is unambiguous proof showing how @MistralAI trains on the test set!\\nGithub NIAH test vs. custom NIAH (procedurally generated facts and questions, instead of using the exact strings from the repo) https://t.co/EhowCWkKYf\" / X', 'ARC Prize - What is ARC-AGI?', 'GPQA: A Graduate-Level Google-Proof Q&A Benchmark', 'Michelangelo: Long Context Evaluations Beyond Haystacks via Latent Structure Queries', '2024 in Open Models [LS Live @ NeurIPS]', '[AINews] Olympus has dropped (aka, Amazon Nova Micro|Lite|Pro|Premier|Canvas|Reel)', 'Phi-4 Technical Report', \"[AINews] Nemotron-4-340B: NVIDIA's new large open models, built on syndata, great for syndata\", 'Cohere Command Models: AI-Powered Solutions for Enterprise', 'Apple Intelligence Foundation Language Models', 'Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models', 'A little pooling goes a long way for multi-vector representations â€“ Answer.AI', 'NeoBERT: A Next-Generation BERT', 'Learning Transferable Visual Models From Natural Language Supervision', 'You Only Look Once: Unified, Real-Time Object Detection', 'swyx on X: \"here\\'s every memory paper, MECE\\'d. https://t.co/wexDcLkVU2\" / X', 'ReAct: Synergizing Reasoning and Acting in Language Models', 'SWE-bench: Can Language Models Resolve Real-World GitHub Issues?', 'FACTS About Building Retrieval Augmented Generation-based Chatbots', 'Instruction-Following Evaluation for Large Language Models', 'Measuring Mathematical Problem Solving With the MATH Dataset', 'GitHub - gkamradt/LLMTest_NeedleInAHaystack: Doing simple retrieval from LLM models at various context lengths to measure accuracy', 'Measuring Massive Multitask Language Understanding', 'Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them', 'Sebastian Raschka on X: \"Updated &amp; turned my Big LLM Architecture Comparison article into a narrated video lecture. \\n\\nThe 11 LLM architectures covered in this video:\\n1. DeepSeek V3/R1\\n2. OLMo 2\\n3. Gemma 3 \\n4. Mistral Small 3.1\\n5. Llama 4\\n6. Qwen3\\n7. SmolLM3\\n8. Kimi 2\\n9. GPT-OSS\\n10. Grok 2.5\\n11. GLM-4.5 https://t.co/POjLPWainM\" / X', 'Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering', 'MemGPT: Towards LLMs as Operating Systems', 'The Power of Scale for Parameter-Efficient Prompt Tuning', 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'] 59\n",
      "['ai', 'reasoning', 'reinforcement', 'experts', 'intelligence', 'supervision', 'learning', 'exploration', 'agents', 'knowledge', 'training', 'understanding'] 12\n"
     ]
    }
   ],
   "source": [
    "clus_4_df = cleaned_df[cleaned_df[\"cluster\"] == 4]\n",
    "\n",
    "clus_tags_df = clus_4_df[[\"tag_id\", \"key\"]].drop_duplicates()\n",
    "clus_tags = clus_tags_df[\"key\"].unique().tolist()\n",
    "\n",
    "clus_bookmarks_df = clus_4_df[[\"bookmark_id\",\"title\", \"description\", \"language\", \"created_at\", \"updated_at\"]].drop_duplicates()\n",
    "clus_titles = clus_bookmarks_df[\"title\"].unique().tolist()\n",
    "\n",
    "print(clus_titles, len(clus_titles))\n",
    "print(clus_tags, len(clus_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d81e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tag_keys_df with the filtered_df on tag_id\n",
    "# joined_df = pd.merge(tag_keys_df, filtered_df, on=\"tag_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beea2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar key groups found:\n",
      "Group 1: ['ai', 'api']\n",
      "Counts: {'ai': 43, 'api': 25}\n",
      "\n",
      "Group 2: ['model', 'models']\n",
      "Counts: {'model': 42, 'models': 30}\n",
      "\n",
      "Group 3: ['learning', 'deeplearning']\n",
      "Counts: {'learning': 37, 'deeplearning': 27}\n",
      "\n",
      "Group 4: ['evaluation', 'evaluations']\n",
      "Counts: {'evaluation': 26, 'evaluations': 4}\n",
      "\n",
      "Group 5: ['mathematics', 'mathematical']\n",
      "Counts: {'mathematics': 25, 'mathematical': 6}\n",
      "\n",
      "Group 6: ['benchmarks', 'benchmark', 'benchmarking']\n",
      "Counts: {'benchmarks': 19, 'benchmark': 11, 'benchmarking': 5}\n",
      "\n",
      "Group 7: ['agents', 'agent']\n",
      "Counts: {'agents': 19, 'agent': 3}\n",
      "\n",
      "Group 8: ['segmentation', 'augmentation']\n",
      "Counts: {'segmentation': 17, 'augmentation': 11}\n",
      "\n",
      "Group 9: ['embeddings', 'embedding']\n",
      "Counts: {'embeddings': 16, 'embedding': 8}\n",
      "\n",
      "Group 10: ['datasets', 'dataset']\n",
      "Counts: {'datasets': 15, 'dataset': 4}\n",
      "\n",
      "Group 11: ['videos', 'video']\n",
      "Counts: {'videos': 15, 'video': 1}\n",
      "\n",
      "Group 12: ['prompt', 'prompting']\n",
      "Counts: {'prompt': 13, 'prompting': 6}\n",
      "\n",
      "Group 13: ['systems', 'system']\n",
      "Counts: {'systems': 13, 'system': 7}\n",
      "\n",
      "Group 14: ['problem', 'problems']\n",
      "Counts: {'problem': 12, 'problems': 9}\n",
      "\n",
      "Group 15: ['mistral', 'mixtral']\n",
      "Counts: {'mistral': 11, 'mixtral': 9}\n",
      "\n",
      "Group 16: ['proof', 'proofs']\n",
      "Counts: {'proof': 9, 'proofs': 4}\n",
      "\n",
      "Group 17: ['power', 'powers']\n",
      "Counts: {'power': 7, 'powers': 4}\n",
      "\n",
      "Keys to keep: {'systems', 'problem', 'evaluation', 'ai', 'agents', 'prompt', 'mathematics', 'power', 'segmentation', 'embeddings', 'learning', 'datasets', 'videos', 'proof', 'benchmarks', 'model', 'mistral'}\n",
      "Keys to drop: {'benchmarking', 'video', 'embedding', 'benchmark', 'augmentation', 'system', 'problems', 'proofs', 'api', 'agent', 'dataset', 'mixtral', 'powers', 'mathematical', 'deeplearning', 'prompting', 'evaluations', 'models'}\n",
      "\n",
      "Original rows: 171\n",
      "Filtered rows: 152\n",
      "Rows removed: 19\n",
      "\n",
      "Filtered bookmark counts:\n",
      "                                  tag_id          key         name  \\\n",
      "0   00608d78-5556-4e9a-8b0c-ce2796f9f13d         qwen         qwen   \n",
      "1   006adf0c-c6bc-44b3-90f6-cc9f524a90e0  challenging  challenging   \n",
      "2   03b8761c-7c70-42d5-bf1a-e04aa63c36b5      testing      testing   \n",
      "3   07db4626-c83f-4ac5-86d4-e49ab2af51a0      scaling      scaling   \n",
      "4   07e2bc25-09ac-4491-bd68-b52bbbf29059    detection    detection   \n",
      "6   0a1692b0-7c39-4b51-98bb-00ae80a6a78f        llama        llama   \n",
      "7   0ba5b21c-898f-4d54-80cc-4e9b23429b89      pooling      pooling   \n",
      "9   0f1ded92-3a77-4315-b72e-3adf525ca586   evaluation   evaluation   \n",
      "10  0f3b9e01-f2fd-4792-aac6-cdc8a6e76544       github       github   \n",
      "11  0fad64f2-a483-4053-aa38-b819a7b7e2df       nvidia       nvidia   \n",
      "\n",
      "    bookmark_count  \n",
      "0                1  \n",
      "1                2  \n",
      "2               12  \n",
      "3               29  \n",
      "4               21  \n",
      "6                1  \n",
      "7                1  \n",
      "9               26  \n",
      "10              12  \n",
      "11               2  \n"
     ]
    }
   ],
   "source": [
    "# NOT NEEDED\n",
    "\n",
    "# Find non-unique keys and drop rows with least bookmark count\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "def similarity(a, b):\n",
    "    \"\"\"Calculate similarity between two strings\"\"\"\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "def find_similar_keys(df, threshold=0.8):\n",
    "    \"\"\"Find groups of similar keys and keep only the one with highest bookmark count\"\"\"\n",
    "    \n",
    "    # Get unique keys with their counts\n",
    "    key_counts = df.groupby('key')['bookmark_count'].sum().reset_index()\n",
    "    key_counts = key_counts.sort_values('bookmark_count', ascending=False)\n",
    "    \n",
    "    # Find similar key groups\n",
    "    similar_groups = []\n",
    "    processed_keys = set()\n",
    "    \n",
    "    for i, row1 in key_counts.iterrows():\n",
    "        if row1['key'] in processed_keys:\n",
    "            continue\n",
    "            \n",
    "        similar_keys = [row1['key']]\n",
    "        processed_keys.add(row1['key'])\n",
    "        \n",
    "        for j, row2 in key_counts.iterrows():\n",
    "            if i != j and row2['key'] not in processed_keys:\n",
    "                if similarity(row1['key'], row2['key']) >= threshold:\n",
    "                    similar_keys.append(row2['key'])\n",
    "                    processed_keys.add(row2['key'])\n",
    "        \n",
    "        if len(similar_keys) > 1:\n",
    "            similar_groups.append(similar_keys)\n",
    "    \n",
    "    return similar_groups, key_counts\n",
    "\n",
    "# Find similar key groups\n",
    "similar_groups, key_counts = find_similar_keys(bookmark_counts, threshold=0.8)\n",
    "\n",
    "print(\"Similar key groups found:\")\n",
    "for i, group in enumerate(similar_groups):\n",
    "    print(f\"Group {i+1}: {group}\")\n",
    "    \n",
    "    # Show counts for each key in the group\n",
    "    group_counts = key_counts[key_counts['key'].isin(group)]\n",
    "    print(f\"Counts: {dict(zip(group_counts['key'], group_counts['bookmark_count']))}\")\n",
    "    print()\n",
    "\n",
    "# Create a list of keys to keep (highest count from each similar group)\n",
    "keys_to_keep = set()\n",
    "keys_to_drop = set()\n",
    "\n",
    "for group in similar_groups:\n",
    "    group_counts = key_counts[key_counts['key'].isin(group)]\n",
    "    # Keep the key with highest count\n",
    "    best_key = group_counts.loc[group_counts['bookmark_count'].idxmax(), 'key']\n",
    "    keys_to_keep.add(best_key)\n",
    "    \n",
    "    # Mark others for dropping\n",
    "    for key in group:\n",
    "        if key != best_key:\n",
    "            keys_to_drop.add(key)\n",
    "\n",
    "print(f\"Keys to keep: {keys_to_keep}\")\n",
    "print(f\"Keys to drop: {keys_to_drop}\")\n",
    "\n",
    "# Filter the dataframe to remove rows with keys that should be dropped\n",
    "filtered_bookmark_counts = bookmark_counts[~bookmark_counts['key'].isin(keys_to_drop)]\n",
    "\n",
    "print(f\"\\nOriginal rows: {len(bookmark_counts)}\")\n",
    "print(f\"Filtered rows: {len(filtered_bookmark_counts)}\")\n",
    "print(f\"Rows removed: {len(bookmark_counts) - len(filtered_bookmark_counts)}\")\n",
    "\n",
    "print(\"\\nFiltered bookmark counts:\")\n",
    "print(filtered_bookmark_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8345b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2 16 16  4  6  4  5 14  1  0 18  5 17  4  8  8  3  2  1  4  1  2 17\n",
      " 11  3  2  8 11 14  5  3  1 15  6  0  0  0  5  0  4  4  5  0 17  5  3  0\n",
      "  2  4  5  0  6  1  5 12  0 11  4  5 11 15  1  5 16  7  6  6 11 10  1  9\n",
      " 10  7  8 15  6 16  2 14  2 13 10  2  2 11  4  5  7 13  5  5  3  2  9  9\n",
      " 12  4 15 16 16  5 10 18 10  2  6 16  7  4  9  9]\n",
      "ChatCompletion(id='chatcmpl-CTveAqKf7HOZfODXYSt0Za1qSiqwm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Reasoning and Learning for AI Agents\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249142, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=1339, total_tokens=1351, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 4: \"Advancements in Reasoning and Learning for AI Agents\"\n",
      "ChatCompletion(id='chatcmpl-CTveC8GPhZbsqzSTkUSleNh8gKorl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Evaluating Efficiency and Capabilities in Advanced Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249144, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=1350, total_tokens=1362, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 2: \"Evaluating Efficiency and Capabilities in Advanced Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveGEA6E1b7EVrqemOXJ6boWljYB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Retrieval-Augmented Generation for Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249148, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=1287, total_tokens=1299, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 16: \"Advancements in Retrieval-Augmented Generation for Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveIdsrz6M6CWyl7lT4pSJGGK1fz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Architectural Innovations in Unified Language Model Development\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249150, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=10, prompt_tokens=1295, total_tokens=1305, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 6: \"Architectural Innovations in Unified Language Model Development\"\n",
      "ChatCompletion(id='chatcmpl-CTveIZKcCKWs4jlRyVpk3wYZp9zcT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Contextual Large Language Model Curation and Evaluation\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249150, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=14, prompt_tokens=1325, total_tokens=1339, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 5: \"Advancements in Contextual Large Language Model Curation and Evaluation\"\n",
      "ChatCompletion(id='chatcmpl-CTveLwwEccI4jCPaDuny7lQSFsyeL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Conversational AI and Language Model Applications\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249153, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=822, total_tokens=834, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 14: \"Advancements in Conversational AI and Language Model Applications\"\n",
      "ChatCompletion(id='chatcmpl-CTveM9O6Fdn1VwKRA9W8RqzmfVe1m', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Integrating Language Models into Programming Workflows and Tools\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249154, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=1001, total_tokens=1013, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 1: \"Integrating Language Models into Programming Workflows and Tools\"\n",
      "ChatCompletion(id='chatcmpl-CTveNGQwMlUS2RLjEtpJeIpqEiRrk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Real-Time Visual Recognition and Segmentation Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249155, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=13, prompt_tokens=948, total_tokens=961, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 0: \"Advancements in Real-Time Visual Recognition and Segmentation Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveOdwIug7fb2DL6INLA1S1g1b3i', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Mathematical Reasoning for Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249156, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=11, prompt_tokens=572, total_tokens=583, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 18: \"Advancements in Mathematical Reasoning for Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTvePaGXTOCBnFWgVLW2RuWVMPrfv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Large Language Models and their Applications\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249157, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=11, prompt_tokens=1062, total_tokens=1073, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 17: \"Advancements in Large Language Models and their Applications\"\n",
      "ChatCompletion(id='chatcmpl-CTveQGeOTasrb0Ew0NhRmcx0n4sWk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Open-Source Language Models and Hallucination Mitigation\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249158, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=16, prompt_tokens=725, total_tokens=741, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 8: \"Advancements in Open-Source Language Models and Hallucination Mitigation\"\n",
      "ChatCompletion(id='chatcmpl-CTveRSIS5vXYz263R9G9DrjktIkPe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Optimization Strategies for Scaling Language Model Performance\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249159, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=9, prompt_tokens=1101, total_tokens=1110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 3: \"Optimization Strategies for Scaling Language Model Performance\"\n",
      "ChatCompletion(id='chatcmpl-CTveS2pcb5NP55XhugSfrvNY3uMvr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Open-Source Large Language Model Architectures\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249160, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=13, prompt_tokens=892, total_tokens=905, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 11: \"Advancements in Open-Source Large Language Model Architectures\"\n",
      "ChatCompletion(id='chatcmpl-CTveTSUgNn0ZafDlMp45Y3KA62JuG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Evaluating Large Language Models: Techniques and Performance Metrics\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249161, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=591, total_tokens=603, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 15: \"Evaluating Large Language Models: Techniques and Performance Metrics\"\n",
      "ChatCompletion(id='chatcmpl-CTveUk54ezzYmpuu1Dr9crI9gW3Ye', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Prompt Engineering for Language Model Applications\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249162, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=11, prompt_tokens=387, total_tokens=398, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 12: \"Advancements in Prompt Engineering for Language Model Applications\"\n",
      "ChatCompletion(id='chatcmpl-CTveWPrrCZMQAJSKsv2aJpmvJGlwA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Multitask Learning for Large Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249164, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=13, prompt_tokens=752, total_tokens=765, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 7: \"Advancements in Multitask Learning for Large Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveXAKFb9vUT6s2HKgP0xNShKzEJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Evaluation Metrics and Benchmarks for Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249165, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=10, prompt_tokens=898, total_tokens=908, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 10: \"Evaluation Metrics and Benchmarks for Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveYgXexVSxW9ocBUOx0Ah3MnwXe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Evaluating Problem-Solving Capabilities of Large Language Models\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249166, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=14, prompt_tokens=659, total_tokens=673, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 9: \"Evaluating Problem-Solving Capabilities of Large Language Models\"\n",
      "ChatCompletion(id='chatcmpl-CTveZZDKNomWPUBx7ivfUoY2qfDpP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\"Advancements in Embedding Models for Natural Language Processing\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761249167, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=12, prompt_tokens=687, total_tokens=699, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Cluster 13: \"Advancements in Embedding Models for Natural Language Processing\"\n",
      "                                 tag_id  cluster  \\\n",
      "0  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "1  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "2  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "3  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "4  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "5  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "6  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "7  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "8  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "9  d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "\n",
      "                            bookmark_id  \\\n",
      "0  a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "1  06ba62ab-870f-432a-87a6-a5be07f7b2e6   \n",
      "2  802b1856-b4cf-4b0b-bcac-b65149c9213a   \n",
      "3  1785c3fe-0ec1-4208-ada2-f0366d510e1a   \n",
      "4  94c217e4-d35f-442d-9d76-6a2561b15caf   \n",
      "5  f6a8e377-0b53-4f09-bf43-777582c77721   \n",
      "6  9006090a-94ba-4ee4-b92b-a57e2ff0f508   \n",
      "7  00897913-7341-4b14-b64e-5cf88725e274   \n",
      "8  80095e27-6b62-4ff4-84f6-5c942b64d59e   \n",
      "9  8afb7bbd-e072-436f-8811-2664fc9bedcb   \n",
      "\n",
      "                                                 url  \\\n",
      "0             https://www.latent.space/p/2025-papers   \n",
      "1  https://www.interconnects.ai/p/papers-im-readi...   \n",
      "2                  https://openai.com/index/chatgpt/   \n",
      "3            https://www.latent.space/p/realtime-api   \n",
      "4                   https://arxiv.org/abs/2402.03300   \n",
      "5                   https://arxiv.org/abs/2401.04088   \n",
      "6                   https://arxiv.org/abs/2410.07073   \n",
      "7                   https://arxiv.org/abs/2401.14196   \n",
      "8                   https://arxiv.org/abs/2401.02954   \n",
      "9                   https://arxiv.org/abs/2310.06825   \n",
      "\n",
      "                                               title  \\\n",
      "0               The 2025 AI Engineering Reading List   \n",
      "1  Recent reasoning research: GRPO tweaks, base m...   \n",
      "2                                Introducing ChatGPT   \n",
      "3            OpenAI Realtime API: The Missing Manual   \n",
      "4  DeepSeekMath: Pushing the Limits of Mathematic...   \n",
      "5                                 Mixtral of Experts   \n",
      "6                                        Pixtral 12B   \n",
      "7  DeepSeek-Coder: When the Large Language Model ...   \n",
      "8  DeepSeek LLM: Scaling Open-Source Language Mod...   \n",
      "9                                         Mistral 7B   \n",
      "\n",
      "                                         description language  \\\n",
      "0  We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "1  The papers I endorse as worth reading among a ...       en   \n",
      "2  Weâ€™ve trained a model called ChatGPT which int...    en-US   \n",
      "3  Everything we learned, and everything we think...       en   \n",
      "4  Mathematical reasoning poses a significant cha...       en   \n",
      "5  We introduce Mixtral 8x7B, a Sparse Mixture of...       en   \n",
      "6  We introduce Pixtral-12B, a 12--billion-parame...       en   \n",
      "7  The rapid development of large language models...       en   \n",
      "8  The rapid development of open-source large lan...       en   \n",
      "9  We introduce Mistral 7B v0.1, a 7-billion-para...       en   \n",
      "\n",
      "               created_at              updated_at key name  \\\n",
      "0 2025-10-23 12:35:18.812 2025-10-23 12:35:18.812  ai   ai   \n",
      "1 2025-10-23 12:35:36.480 2025-10-23 12:35:36.480  ai   ai   \n",
      "2 2025-10-23 12:36:13.336 2025-10-23 12:36:13.336  ai   ai   \n",
      "3 2025-10-23 12:36:16.386 2025-10-23 12:36:16.386  ai   ai   \n",
      "4 2025-10-23 12:41:13.177 2025-10-23 12:41:13.177  ai   ai   \n",
      "5 2025-10-23 12:41:40.828 2025-10-23 12:41:40.828  ai   ai   \n",
      "6 2025-10-23 12:41:43.611 2025-10-23 12:41:43.611  ai   ai   \n",
      "7 2025-10-23 12:41:32.368 2025-10-23 12:41:32.368  ai   ai   \n",
      "8 2025-10-23 12:41:36.609 2025-10-23 12:41:36.609  ai   ai   \n",
      "9 2025-10-23 12:41:46.997 2025-10-23 12:41:46.997  ai   ai   \n",
      "\n",
      "                                               topic  \n",
      "0  \"Advancements in Reasoning and Learning for AI...  \n",
      "1  \"Advancements in Reasoning and Learning for AI...  \n",
      "2  \"Advancements in Reasoning and Learning for AI...  \n",
      "3  \"Advancements in Reasoning and Learning for AI...  \n",
      "4  \"Advancements in Reasoning and Learning for AI...  \n",
      "5  \"Advancements in Reasoning and Learning for AI...  \n",
      "6  \"Advancements in Reasoning and Learning for AI...  \n",
      "7  \"Advancements in Reasoning and Learning for AI...  \n",
      "8  \"Advancements in Reasoning and Learning for AI...  \n",
      "9  \"Advancements in Reasoning and Learning for AI...  \n",
      "                                    tag_id  cluster  \\\n",
      "0     d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "1     d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "2     d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "3     d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "4     d73bda20-81cf-4ac2-8d73-f782b68a1901        4   \n",
      "...                                    ...      ...   \n",
      "1984  5fe40731-7bf9-4b73-9e15-bb26b07ac559        9   \n",
      "1985  5fe40731-7bf9-4b73-9e15-bb26b07ac559        9   \n",
      "1986  5fe40731-7bf9-4b73-9e15-bb26b07ac559        9   \n",
      "1987  5fe40731-7bf9-4b73-9e15-bb26b07ac559        9   \n",
      "1988  5fe40731-7bf9-4b73-9e15-bb26b07ac559        9   \n",
      "\n",
      "                               bookmark_id  \\\n",
      "0     a4f37ecc-172a-48e4-8570-8d059398d77d   \n",
      "1     06ba62ab-870f-432a-87a6-a5be07f7b2e6   \n",
      "2     802b1856-b4cf-4b0b-bcac-b65149c9213a   \n",
      "3     1785c3fe-0ec1-4208-ada2-f0366d510e1a   \n",
      "4     94c217e4-d35f-442d-9d76-6a2561b15caf   \n",
      "...                                    ...   \n",
      "1984  e5852544-9fb7-4d34-9768-736387a816db   \n",
      "1985  60472740-769d-4190-a04d-5e3ec64ccf82   \n",
      "1986  0b741823-9de2-4d08-b03a-76c6306aa8ba   \n",
      "1987  c6c0d547-a5de-4d68-9a48-c2f0e84755c4   \n",
      "1988  d8ae06ab-0b62-4115-86c8-7153834e142a   \n",
      "\n",
      "                                                    url  \\\n",
      "0                https://www.latent.space/p/2025-papers   \n",
      "1     https://www.interconnects.ai/p/papers-im-readi...   \n",
      "2                     https://openai.com/index/chatgpt/   \n",
      "3               https://www.latent.space/p/realtime-api   \n",
      "4                      https://arxiv.org/abs/2402.03300   \n",
      "...                                                 ...   \n",
      "1984                         https://cohere.com/command   \n",
      "1985                   https://arxiv.org/abs/2407.21075   \n",
      "1986                   https://arxiv.org/abs/2409.17146   \n",
      "1987  https://x.com/rasbt/status/1965798055141429523...   \n",
      "1988                   https://arxiv.org/abs/2502.19587   \n",
      "\n",
      "                                                  title  \\\n",
      "0                  The 2025 AI Engineering Reading List   \n",
      "1     Recent reasoning research: GRPO tweaks, base m...   \n",
      "2                                   Introducing ChatGPT   \n",
      "3               OpenAI Realtime API: The Missing Manual   \n",
      "4     DeepSeekMath: Pushing the Limits of Mathematic...   \n",
      "...                                                 ...   \n",
      "1984  Cohere Command Models: AI-Powered Solutions fo...   \n",
      "1985      Apple Intelligence Foundation Language Models   \n",
      "1986  Molmo and PixMo: Open Weights and Open Data fo...   \n",
      "1987  Sebastian Raschka on X: \"Updated &amp; turned ...   \n",
      "1988                    NeoBERT: A Next-Generation BERT   \n",
      "\n",
      "                                            description language  \\\n",
      "0     We picked 50 paper/models/blogs across 10 fiel...       en   \n",
      "1     The papers I endorse as worth reading among a ...       en   \n",
      "2     Weâ€™ve trained a model called ChatGPT which int...    en-US   \n",
      "3     Everything we learned, and everything we think...       en   \n",
      "4     Mathematical reasoning poses a significant cha...       en   \n",
      "...                                                 ...      ...   \n",
      "1984  Cohere Command is a family of highly scalable ...    en-US   \n",
      "1985  We present foundation language models develope...       en   \n",
      "1986  Today's most advanced vision-language models (...       en   \n",
      "1987                                                          en   \n",
      "1988  Recent innovations in architecture, pre-traini...       en   \n",
      "\n",
      "                  created_at              updated_at        key       name  \\\n",
      "0    2025-10-23 12:35:18.812 2025-10-23 12:35:18.812         ai         ai   \n",
      "1    2025-10-23 12:35:36.480 2025-10-23 12:35:36.480         ai         ai   \n",
      "2    2025-10-23 12:36:13.336 2025-10-23 12:36:13.336         ai         ai   \n",
      "3    2025-10-23 12:36:16.386 2025-10-23 12:36:16.386         ai         ai   \n",
      "4    2025-10-23 12:41:13.177 2025-10-23 12:41:13.177         ai         ai   \n",
      "...                      ...                     ...        ...        ...   \n",
      "1984 2025-10-23 12:47:05.453 2025-10-23 12:47:05.453  solutions  solutions   \n",
      "1985 2025-10-23 12:47:08.473 2025-10-23 12:47:08.473  solutions  solutions   \n",
      "1986 2025-10-23 12:47:11.455 2025-10-23 12:47:11.455  solutions  solutions   \n",
      "1987 2025-10-23 12:47:50.008 2025-10-23 12:47:50.008  solutions  solutions   \n",
      "1988 2025-10-23 12:47:54.080 2025-10-23 12:47:54.080  solutions  solutions   \n",
      "\n",
      "                                                  topic  \n",
      "0     \"Advancements in Reasoning and Learning for AI...  \n",
      "1     \"Advancements in Reasoning and Learning for AI...  \n",
      "2     \"Advancements in Reasoning and Learning for AI...  \n",
      "3     \"Advancements in Reasoning and Learning for AI...  \n",
      "4     \"Advancements in Reasoning and Learning for AI...  \n",
      "...                                                 ...  \n",
      "1984  \"Evaluating Problem-Solving Capabilities of La...  \n",
      "1985  \"Evaluating Problem-Solving Capabilities of La...  \n",
      "1986  \"Evaluating Problem-Solving Capabilities of La...  \n",
      "1987  \"Evaluating Problem-Solving Capabilities of La...  \n",
      "1988  \"Evaluating Problem-Solving Capabilities of La...  \n",
      "\n",
      "[1989 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from topic_gen.topic_gen import TopicGen\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "user_id = \"8c525b6b-27c9-4379-a454-2c3b3a781124\"\n",
    "\n",
    "topic_gen = TopicGen()\n",
    "\n",
    "out_df = topic_gen.generate(user_id)\n",
    "print(out_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
